---
categories: blog
published: true
title: "Surveillance Capital & Nonprofit Tech with Allen Gunn"
author: Karissa McKelvey
tags:
  - featured
  - front-page
image: /assets/.jpeg
excerpt: ""
---

This week, I was able to sit down with Allen Gunn, the Executive Director of
[Aspiration Tech](www.aspirationtech.org) in San Francisco, USA. He works to
help NGOs, activists, foundations and software developers make more effective
use of technology for social change.

The common thread that connects all facets of Gunner's work is a focus on open
approaches to capacity building and knowledge sharing in social change efforts.
We wanted to speak with him as part of our new Technology Solidarity series,
where we're taking a moment to explore what we've learned in conversation with
others working at the intersection of technology and human rights.

### K: You have a 10,000-foot view of this space. What do you think are the most pressing issues regarding technology for social change?  

*Gunner*: I'm trying to birth a paper about controlling our digital destiny -- about
having alternative infrastructure that we actually control. So much about what
we're trying to do is move away from talking about technology, and more towards
talking about data. The anthology of the non-profit sector is that technology
gets line-items & budgets, but data is not part of that conversation. In other
words, they worry more about the tech than the data. We are looking to flip that narrative.

From a game theoretic standpoint, we've already lost. For example, if you're in
a room with a toddler who just locked into something, you can see their eyes,
and you know their future. If it's an inanimate object, you've got to get the
camera.  If it's an electrical socket, you see that they're going to put their
finger in it -- you intervene. If it's an animal, you do a threat model. Is the
cat cute or will it scratch the kid's face off? By putting the data in the
corporate cloud, we are that kid. We are giving corporations and governments
a way to see where we are looking towards, and they can predict our future. 

The best options for cloud software are not open source, and the cost is giving up all
of our data. We are addicted to phones that track us 24/7 and know everything
we do. Idiots -- and you can quote me on that -- continue to buy home
surveillance-ware and hardware... so we are trending in all the wrong
directions. We should be fighting hard to not have our data in the control of
governments.

If you want to talk about impact stories for non-profit and civil society, you
need to understand what is at risk and stand in solidarity with those
who are practicing data minimalism and data solidarity. 

### K: Where are the biggest gaps in practicing data solidarity? 

*Gunner*: A complete understanding of the social graph we carry with us is a huge
one that people still don't fully get. Data solidarity means how my social
graph toxifies other people's social graphs, and puts them in danger. For
example, I hosted Freedom of the Press, Edward Snowden's organization, we've
hosted Tor meetings, etc. If I make a clear social graph connection with
someone from a marginalized community, am I putting them at risk? If suddenly
the government wants to trace my social graph and incriminate anyone I had
collaborated with, it would be really easy for them. This could affect
their visa, job, throw them in jail, or worse. The unknown future costs
of data can not be calculated. So for everyone out there, that means having
good data retention policies -- for example, do you save participant lists from
your events forever? 

Many people talk about the ways we might start correlating data practices with
carbon practices. In the same way that carbon in the atmosphere is going to
kill us, data in the digital sphere is going to kill us. DKG says another way
to think about this is to equate data with pesticides. As soon as they're utilized,
we don't know the future harm they could cause. The more data we let get
collected the more future harm we know that is possible -- so try to collect as
little data as possible.

Google Drive accounts are honey pots. A cellphone with Signal on it without
disappearing messages is a honey pot. Increasing our resillience against data
seisure means reducing the number of honey pots.  Although not yet an impact
story, Next Cloud is part of that, it is encrypted and has the right way to
provide these guarantees. There are also a variety of second-order Signal
applications.. for example, signalboost.info. It uses the signal protocol to do
mass notifications for things like protests. It scrapes all metadata, all
numbers in the group are not visible to the recipients. The owner of the Twilio
account still knows all the phone numbers, but it's a step in the right
direction.

### K: As a leader in the non profit techology scene, you must have seen a wide breadth of projects over the years. What projects have had the most impact that are still active today?

*Gunner*: Signal was and still is an emblem of a way to do technology in civil
society. It was a design-first project, meaning the design came first and was
the most important thing to get right from the beginning. The goal was set so
that the user need know nothing about the security that protects them. They
combined this with a hugely talented staff and were able to do really well.
There are very few stories like this in civil society.

Wordpress, the open source content management system, is another example where we
have seen technology win in the sector. Wordpress is a paradigm for what the
open source ecosystem should be. It's open, but still sustainable. You have
options: you can do self-hosting where you control the data, have 3rd party
hosting where you can pay any joe to host your content, or pay the Wordpress
team and get 100% uptime. Wordpress paired this 100% data exportability, which
means I can export my content any time and it's an open standard that easily
implements into other platforms. Even though it's not a non-profit platform,
it's an emblem of how opens ource should be done, which gives users a variety
of options for how they can control their own data. 

### K: For those reading this who are involved in non-profit technology; either supporting an existing project or making a new one, do you have some advice?

*Gunner*: Listen to your users first second third. Technology should come last.
Measure thrice cut once. Don't just do user research and code for a year and
disappear. Test your findings and then give tough love to your plan and let
the findings impact it. 

Be open source & have the governance conversations first. Model for success.
People are going to want to contribute code, money, etc. You need to talk about
how those decisions get made, how those contributions get honored, how do you
federate equity in a project as it scales. For example, see Mozilla's module
architecture. There's a governance list and you can pass on your ownership of
a module. There's always a fallback person if you get hit by a bus. This is
a good example of a federated ownership module.

### K: I'm sure there are many people reading this now who want to do something to help this movement against surveillance capital. What would you say to those who want to enter into this space?

*Gunner*: My first answer is: learn how to be a data steward or data ally.
Help organizations proactively think about what data they do colllct and how it
is governed after its collected. Help organizations get their collective head
around all the data they posess, how they curate it, how they back it up, and
how over time they minimize it.

There's a french proverb that says "The words that you have not spoken; you are their
owner. The words you have spoken, they own you." The data that organizations
commit to digital memory controls them. How can you set up that dynamic to be
the healthiest it can be?  

Don't go to code academy, go to design academy. Be advocates of the user
& consumer. It's not about learning how to code, its about translating
real-world needs to technological specifications. Be a steward of user-centric
design. Learn how to manage data and offer your help.
    
Finally, work on your infmoration security literacy. Learn what a threat model
is & learn how to mitigate threats. Afterall, it's not about the tech, it's about the data.

Remember that tech decisions are political decisions, you are what you use, but
your integrity lies in how you manage your data.
